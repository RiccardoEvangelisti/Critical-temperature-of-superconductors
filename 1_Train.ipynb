{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical Temperature of Superconductors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import itertools\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from utils import Step, Pipe, MultiplePipes\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "DATA_FOLDER = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "# REMOVE_HIGH_CORR_FEATURES = True\n",
    "# CORR_THRESHOLD = 0.95\n",
    "\n",
    "\n",
    "OUTLIER_REMOVAL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of Properties+Formula df:  (17010, 169)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(DATA_FOLDER + \"formula_train.csv\").drop(columns=[\"critical_temp\"]),\n",
    "        pd.read_csv(DATA_FOLDER + \"train.csv\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "print(\"Shapes of Properties+Formula df: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"material\" feature\n",
    "df = df.drop(columns=\"material\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13608, 167), (3402, 167), (13608, 1), (3402, 1))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "X_train = train.drop(columns=[\"critical_temp\"])\n",
    "y_train = train[[\"critical_temp\"]]\n",
    "\n",
    "X_test = test.drop(columns=[\"critical_temp\"])\n",
    "y_test = test[[\"critical_temp\"]]\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Remove Highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if REMOVE_HIGH_CORR_FEATURES:\n",
    "#     corr_matrix = df.corr().abs()\n",
    "#     upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "#     cols_to_drop = [column for column in upper.columns if any(upper[column] >= CORR_THRESHOLD)]\n",
    "\n",
    "#     print(\"{} Cols Removed: {}\".format(len(cols_to_drop), cols_to_drop))\n",
    "#     X_train = X_train.drop(columns=cols_to_drop)\n",
    "#     X_test = X_test.drop(columns=cols_to_drop)\n",
    "#     print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesRemover:\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        corr_matrix = df.corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        cols_to_drop = [column for column in upper.columns if any(upper[column] >= self.corr_threshold)]\n",
    "\n",
    "        # print(\"{} Cols Removed: {}\".format(len(cols_to_drop), cols_to_drop))\n",
    "        X = X.drop(columns=cols_to_drop)\n",
    "        return X\n",
    "\n",
    "    def set_params(self, corr_threshold):\n",
    "        self.corr_threshold = corr_threshold\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OUTLIER_REMOVAL:\n",
    "    columns = train.columns\n",
    "    outliers = pd.Series(index=train.index, dtype=bool)\n",
    "\n",
    "    clf = LocalOutlierFactor(n_jobs=-1)\n",
    "    # clf = IsolationForest(\n",
    "    #     max_samples=1.0,\n",
    "    #     contamination=0.001,\n",
    "    #     n_jobs=-1,\n",
    "    #     random_state=random_state,\n",
    "    # )\n",
    "    outliers = clf.fit_predict(train) == -1\n",
    "\n",
    "    print(\"Outliers removed: {}\".format(outliers.sum()))\n",
    "    train = train[~outliers]\n",
    "\n",
    "    X_train = train.drop(columns=[\"critical_temp\"])\n",
    "    y_train = train[[\"critical_temp\"]]\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class OutliersRemover:\n",
    "#     def __init__(self) -> None:\n",
    "#         self.outliers_vector = None\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         self.outliers_vector = pd.Series(index=X.index, dtype=bool)\n",
    "\n",
    "#         clf = LocalOutlierFactor(n_jobs=-1)\n",
    "#         # clf = IsolationForest(\n",
    "#         #     max_samples=1.0,\n",
    "#         #     contamination=0.001,\n",
    "#         #     n_jobs=-1,\n",
    "#         #     random_state=random_state,\n",
    "#         # )\n",
    "#         self.outliers_vector = clf.fit_predict(np.column_stack((X, y))) == -1\n",
    "#         print(\"Outliers removed: {}\".format(self.outliers_vector.sum()))\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "\n",
    "#         X = X[~self.outliers_vector]\n",
    "#         y = y[~self.outliers_vector]\n",
    "\n",
    "#         print(\"Outliers removed: {}\".format(self.outliers_vector.sum()))\n",
    "#         print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "#         return X, y\n",
    "\n",
    "#     def set_params(self):\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_remover_step = Step(\n",
    "    \"features_remover\",\n",
    "    FeaturesRemover(),\n",
    "    {\"corr_threshold\": 0.95},\n",
    ")\n",
    "std_step = Step(\n",
    "    \"std\",\n",
    "    preprocessing.StandardScaler(),\n",
    ")\n",
    "minmax_step = Step(\n",
    "    \"minmax\",\n",
    "    preprocessing.MinMaxScaler(),\n",
    ")\n",
    "l1_step = Step(\n",
    "    \"l1\",\n",
    "    preprocessing.Normalizer(norm=\"l1\"),\n",
    ")\n",
    "l2_step = Step(\n",
    "    \"l2\",\n",
    "    preprocessing.Normalizer(norm=\"l2\"),\n",
    ")\n",
    "lmax_step = Step(\n",
    "    \"lmax\",\n",
    "    preprocessing.Normalizer(norm=\"max\"),\n",
    ")\n",
    "pca_step = Step(\n",
    "    \"pca\",\n",
    "    PCA(random_state=RANDOM_STATE),\n",
    "    {\n",
    "        \"n_components\": [0.95],\n",
    "        # \"whiten\": [True, False],\n",
    "        # \"svd_solver\": \"full\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(combinations: MultiplePipes, estimator_tag: str, save_results=True):\n",
    "\n",
    "    # Iterate over *all* combinations\n",
    "    for index, (pipeline, parameters, tag) in enumerate(combinations.combinations):\n",
    "        print(\n",
    "            \"Combination {}/{}. Steps: {}\\n\\tParams:{}\".format(\n",
    "                index + 1, len(combinations.combinations), tag, parameters\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if save_results:\n",
    "            file_name = \"outputs/\" + \"1_\" + estimator_tag + \"_output.csv\"\n",
    "            if os.path.isfile(file_name):\n",
    "                outputs = pd.read_csv(file_name)\n",
    "                # if all parameters are present in the output:\n",
    "                if all(x in outputs.columns for x in parameters.keys()):\n",
    "                    outputs = outputs.loc[:, parameters.keys()]\n",
    "                    if outputs.isin(parameters).any(axis=1).any(): # TODO: IL PROBLEMA è CHE OGNI ELEMENTO DEL DIZIONARIO è UNA LISTA, MENTRE NEL DF OVVIAMENTE NO. MA PERCHè FA SEMPRE MATCH???\n",
    "                        print(\"\\tAlready done. Skipped.\")\n",
    "                        continue\n",
    "\n",
    "        gs = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=parameters,\n",
    "            scoring=\"r2\",\n",
    "            n_jobs=-1,\n",
    "            cv=3,\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        # Fit\n",
    "        gs.fit(X_train, np.ravel(y_train))\n",
    "        # Predict\n",
    "        y_pred = gs.predict(X_test)\n",
    "        # Test scores\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(\"MSE: {}\\tR2: {}\".format(mse, r2))\n",
    "\n",
    "        if save_results:\n",
    "            outputs = pd.DataFrame(parameters or None, index=[0])\n",
    "            outputs = outputs.assign(tag=tag, MSE=mse, R2=r2)\n",
    "            outputs = pd.concat(\n",
    "                [pd.read_csv(file_name) if os.path.isfile(file_name) else pd.DataFrame(), outputs], axis=0\n",
    "            )\n",
    "            outputs.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 1/4. Steps: minmax + pca + random_forest\n",
      "\tParams:{'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.01], 'random_forest__max_features': [0.4]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'float' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 20\u001b[0m\n\u001b[1;32m      2\u001b[0m random_forest_step \u001b[38;5;241m=\u001b[39m Step(\n\u001b[1;32m      3\u001b[0m     estimator_tag,\n\u001b[1;32m      4\u001b[0m     RandomForestRegressor(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mRANDOM_STATE),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     },\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m combinations \u001b[38;5;241m=\u001b[39m MultiplePipes(\n\u001b[1;32m     17\u001b[0m     Pipe(minmax_step, pca_step, random_forest_step),\n\u001b[1;32m     18\u001b[0m     Pipe(features_remover_step, minmax_step, pca_step, random_forest_step),\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombinations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator_tag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_tag\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[57], line 19\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(combinations, estimator_tag, save_results)\u001b[0m\n\u001b[1;32m     17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloc[:, parameters\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indice, riga \u001b[38;5;129;01min\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 19\u001b[0m     riga_corrisponde \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalore\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mriga\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchiave\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchiave\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalore\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m riga_corrisponde:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mAlready done. Skipped.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[57], line 19\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloc[:, parameters\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indice, riga \u001b[38;5;129;01min\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 19\u001b[0m     riga_corrisponde \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(\u001b[43mvalore\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mriga\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchiave\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m chiave, valore \u001b[38;5;129;01min\u001b[39;00m parameters\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m riga_corrisponde:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mAlready done. Skipped.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'float' is not iterable"
     ]
    }
   ],
   "source": [
    "estimator_tag = \"random_forest\"\n",
    "random_forest_step = Step(\n",
    "    estimator_tag,\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=RANDOM_STATE),\n",
    "    {\n",
    "        \"max_samples\": [0.66, 0.33],\n",
    "        \"criterion\": [\"squared_error\"],\n",
    "        \"n_estimators\": [200],\n",
    "        \"max_depth\": [25],  # , 5, 10, 15, 20],\n",
    "        \"max_leaf_nodes\": [None],  # 50, 100, 200, 300, 400\n",
    "        \"ccp_alpha\": [0.01],  # 0.0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0\n",
    "        \"max_features\": [0.4],  # \"sqrt\", \"log2\", 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9\n",
    "    },\n",
    ")\n",
    "\n",
    "combinations = MultiplePipes(\n",
    "    Pipe(minmax_step, pca_step, random_forest_step),\n",
    "    Pipe(features_remover_step, minmax_step, pca_step, random_forest_step),\n",
    ")\n",
    "grid_search(combinations, estimator_tag=estimator_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
