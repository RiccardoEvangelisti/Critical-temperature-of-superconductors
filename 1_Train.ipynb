{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical Temperature of Superconductors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from utils import Step, Pipe, MultiplePipes, combination_already_tested, print_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "DATA_FOLDER = \"data/\"\n",
    "OUTPUT_FOLDER = \"outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "OUTLIER_REMOVAL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of Properties+Formula df:  (17010, 169)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(DATA_FOLDER + \"formula_train.csv\").drop(columns=[\"critical_temp\"]),\n",
    "        pd.read_csv(DATA_FOLDER + \"train.csv\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "print(\"Shapes of Properties+Formula df: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"material\" feature\n",
    "df = df.drop(columns=\"material\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13608, 167), (3402, 167), (13608, 1), (3402, 1))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "X_train = train.drop(columns=[\"critical_temp\"])\n",
    "y_train = train[[\"critical_temp\"]]\n",
    "\n",
    "X_test = test.drop(columns=[\"critical_temp\"])\n",
    "y_test = test[[\"critical_temp\"]]\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Remove Highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if REMOVE_HIGH_CORR_FEATURES:\n",
    "#     corr_matrix = df.corr().abs()\n",
    "#     upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "#     cols_to_drop = [column for column in upper.columns if any(upper[column] >= CORR_THRESHOLD)]\n",
    "\n",
    "#     print(\"{} Cols Removed: {}\".format(len(cols_to_drop), cols_to_drop))\n",
    "#     X_train = X_train.drop(columns=cols_to_drop)\n",
    "#     X_test = X_test.drop(columns=cols_to_drop)\n",
    "#     print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesRemover:\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        corr_matrix = df.corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        cols_to_drop = [column for column in upper.columns if any(upper[column] >= self.corr_threshold)]\n",
    "\n",
    "        # print(\"{} Cols Removed: {}\".format(len(cols_to_drop), cols_to_drop))\n",
    "        X = X.drop(columns=cols_to_drop)\n",
    "        return X\n",
    "\n",
    "    def set_params(self, corr_threshold):\n",
    "        self.corr_threshold = corr_threshold\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OUTLIER_REMOVAL:\n",
    "    columns = train.columns\n",
    "    outliers = pd.Series(index=train.index, dtype=bool)\n",
    "\n",
    "    clf = LocalOutlierFactor(n_jobs=-1)\n",
    "    # clf = IsolationForest(\n",
    "    #     max_samples=1.0,\n",
    "    #     contamination=0.001,\n",
    "    #     n_jobs=-1,\n",
    "    #     random_state=random_state,\n",
    "    # )\n",
    "    outliers = clf.fit_predict(train) == -1\n",
    "\n",
    "    print(\"Outliers removed: {}\".format(outliers.sum()))\n",
    "    train = train[~outliers]\n",
    "\n",
    "    X_train = train.drop(columns=[\"critical_temp\"])\n",
    "    y_train = train[[\"critical_temp\"]]\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class OutliersRemover:\n",
    "#     def __init__(self) -> None:\n",
    "#         self.outliers_vector = None\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         self.outliers_vector = pd.Series(index=X.index, dtype=bool)\n",
    "\n",
    "#         clf = LocalOutlierFactor(n_jobs=-1)\n",
    "#         # clf = IsolationForest(\n",
    "#         #     max_samples=1.0,\n",
    "#         #     contamination=0.001,\n",
    "#         #     n_jobs=-1,\n",
    "#         #     random_state=random_state,\n",
    "#         # )\n",
    "#         self.outliers_vector = clf.fit_predict(np.column_stack((X, y))) == -1\n",
    "#         print(\"Outliers removed: {}\".format(self.outliers_vector.sum()))\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None):\n",
    "\n",
    "#         X = X[~self.outliers_vector]\n",
    "#         y = y[~self.outliers_vector]\n",
    "\n",
    "#         print(\"Outliers removed: {}\".format(self.outliers_vector.sum()))\n",
    "#         print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "#         return X, y\n",
    "\n",
    "#     def set_params(self):\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_remover_step = Step(\n",
    "    \"features_remover\",\n",
    "    FeaturesRemover(),\n",
    "    {\"corr_threshold\": 0.95},\n",
    ")\n",
    "std_step = Step(\n",
    "    \"std\",\n",
    "    preprocessing.StandardScaler(),\n",
    ")\n",
    "minmax_step = Step(\n",
    "    \"minmax\",\n",
    "    preprocessing.MinMaxScaler(),\n",
    ")\n",
    "l1_step = Step(\n",
    "    \"l1\",\n",
    "    preprocessing.Normalizer(norm=\"l1\"),\n",
    ")\n",
    "l2_step = Step(\n",
    "    \"l2\",\n",
    "    preprocessing.Normalizer(norm=\"l2\"),\n",
    ")\n",
    "lmax_step = Step(\n",
    "    \"lmax\",\n",
    "    preprocessing.Normalizer(norm=\"max\"),\n",
    ")\n",
    "pca_step = Step(\n",
    "    \"pca\",\n",
    "    PCA(random_state=RANDOM_STATE),\n",
    "    {\n",
    "        \"n_components\": [0.95],\n",
    "        # \"whiten\": [True, False],\n",
    "        # \"svd_solver\": \"full\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(combinations: MultiplePipes, estimator_tag: str, save_results=True):\n",
    "\n",
    "    # Iterate over *all* combinations\n",
    "    for index, (pipeline, parameters, tag) in enumerate(combinations.combinations):\n",
    "        print(\n",
    "            \"\\nCombination {}/{}  |  {}\\n\\tParams {}\".format(index + 1, len(combinations.combinations), tag, parameters)\n",
    "        )\n",
    "\n",
    "        # Check if this combination is already tested\n",
    "        if save_results:\n",
    "            file_name = OUTPUT_FOLDER + estimator_tag + \"_output.csv\"\n",
    "            if combination_already_tested(file_name, parameters, tag):\n",
    "                print(\"  ==> Already done. Skipped.\")\n",
    "                continue\n",
    "\n",
    "        gs = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=parameters,\n",
    "            n_jobs=-1,\n",
    "            cv=3,\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        # Fit\n",
    "        gs.fit(X_train, np.ravel(y_train))\n",
    "        # Predict\n",
    "        y_pred = gs.predict(X_test)\n",
    "        # Test scores\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(\"  ==> R2: {}\\tMSE: {}\".format(r2, mse))\n",
    "\n",
    "        # Save results\n",
    "        if save_results:\n",
    "            outputs = pd.DataFrame(parameters or None, index=[0]).assign(tag=tag, MSE=mse, R2=r2)\n",
    "            outputs = pd.concat(\n",
    "                [pd.read_csv(file_name) if os.path.isfile(file_name) else pd.DataFrame(), outputs], axis=0\n",
    "            )\n",
    "            outputs.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination 1/28  |  random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.0], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 2/28  |  random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [1e-05], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 3/28  |  random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.0001], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 4/28  |  random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.001], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 5/28  |  random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.01], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 6/28  |  random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.1], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 7/28  |  random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [1.0], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 8/28  |  minmax + random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.0], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 9/28  |  minmax + random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [1e-05], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 10/28  |  minmax + random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.0001], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 11/28  |  minmax + random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.001], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 12/28  |  minmax + random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.01], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 13/28  |  minmax + random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.1], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 14/28  |  minmax + random_forest\n",
      "\tParams {'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [1.0], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 15/28  |  minmax + pca + random_forest\n",
      "\tParams {'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.0], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 16/28  |  minmax + pca + random_forest\n",
      "\tParams {'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [1e-05], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 17/28  |  minmax + pca + random_forest\n",
      "\tParams {'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.0001], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 18/28  |  minmax + pca + random_forest\n",
      "\tParams {'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.001], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 19/28  |  minmax + pca + random_forest\n",
      "\tParams {'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.01], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 20/28  |  minmax + pca + random_forest\n",
      "\tParams {'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.1], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 21/28  |  minmax + pca + random_forest\n",
      "\tParams {'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [1.0], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 22/28  |  features_remover + minmax + pca + random_forest\n",
      "\tParams {'features_remover__corr_threshold': [0.95], 'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.0], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 23/28  |  features_remover + minmax + pca + random_forest\n",
      "\tParams {'features_remover__corr_threshold': [0.95], 'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [1e-05], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 24/28  |  features_remover + minmax + pca + random_forest\n",
      "\tParams {'features_remover__corr_threshold': [0.95], 'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.0001], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 25/28  |  features_remover + minmax + pca + random_forest\n",
      "\tParams {'features_remover__corr_threshold': [0.95], 'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.001], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 26/28  |  features_remover + minmax + pca + random_forest\n",
      "\tParams {'features_remover__corr_threshold': [0.95], 'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.01], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 27/28  |  features_remover + minmax + pca + random_forest\n",
      "\tParams {'features_remover__corr_threshold': [0.95], 'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [0.1], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 28/28  |  features_remover + minmax + pca + random_forest\n",
      "\tParams {'features_remover__corr_threshold': [0.95], 'pca__n_components': [0.95], 'random_forest__max_samples': [0.66], 'random_forest__criterion': ['squared_error'], 'random_forest__n_estimators': [200], 'random_forest__max_depth': [25], 'random_forest__max_leaf_nodes': [None], 'random_forest__ccp_alpha': [1.0], 'random_forest__max_features': [0.4]}\n",
      "  ==> Already done. Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_60463\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_60463_level0_col0\" class=\"col_heading level0 col0\" >tag</th>\n",
       "      <th id=\"T_60463_level0_col1\" class=\"col_heading level0 col1\" >R2</th>\n",
       "      <th id=\"T_60463_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_60463_level0_col3\" class=\"col_heading level0 col3\" >random_forest__max_samples</th>\n",
       "      <th id=\"T_60463_level0_col4\" class=\"col_heading level0 col4\" >random_forest__criterion</th>\n",
       "      <th id=\"T_60463_level0_col5\" class=\"col_heading level0 col5\" >random_forest__n_estimators</th>\n",
       "      <th id=\"T_60463_level0_col6\" class=\"col_heading level0 col6\" >random_forest__max_depth</th>\n",
       "      <th id=\"T_60463_level0_col7\" class=\"col_heading level0 col7\" >random_forest__max_leaf_nodes</th>\n",
       "      <th id=\"T_60463_level0_col8\" class=\"col_heading level0 col8\" >random_forest__ccp_alpha</th>\n",
       "      <th id=\"T_60463_level0_col9\" class=\"col_heading level0 col9\" >random_forest__max_features</th>\n",
       "      <th id=\"T_60463_level0_col10\" class=\"col_heading level0 col10\" >pca__n_components</th>\n",
       "      <th id=\"T_60463_level0_col11\" class=\"col_heading level0 col11\" >features_remover__corr_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_60463_level0_row0\" class=\"row_heading level0 row0\" >55</th>\n",
       "      <td id=\"T_60463_row0_col0\" class=\"data row0 col0\" >minmax + random_forest</td>\n",
       "      <td id=\"T_60463_row0_col1\" class=\"data row0 col1\" >0.9268</td>\n",
       "      <td id=\"T_60463_row0_col2\" class=\"data row0 col2\" >83.2720</td>\n",
       "      <td id=\"T_60463_row0_col3\" class=\"data row0 col3\" >0.6600</td>\n",
       "      <td id=\"T_60463_row0_col4\" class=\"data row0 col4\" >squared_error</td>\n",
       "      <td id=\"T_60463_row0_col5\" class=\"data row0 col5\" >200</td>\n",
       "      <td id=\"T_60463_row0_col6\" class=\"data row0 col6\" >25</td>\n",
       "      <td id=\"T_60463_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_60463_row0_col8\" class=\"data row0 col8\" >0.0000</td>\n",
       "      <td id=\"T_60463_row0_col9\" class=\"data row0 col9\" >0.4000</td>\n",
       "      <td id=\"T_60463_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_60463_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60463_level0_row1\" class=\"row_heading level0 row1\" >54</th>\n",
       "      <td id=\"T_60463_row1_col0\" class=\"data row1 col0\" >minmax + random_forest</td>\n",
       "      <td id=\"T_60463_row1_col1\" class=\"data row1 col1\" >0.9268</td>\n",
       "      <td id=\"T_60463_row1_col2\" class=\"data row1 col2\" >83.2731</td>\n",
       "      <td id=\"T_60463_row1_col3\" class=\"data row1 col3\" >0.6600</td>\n",
       "      <td id=\"T_60463_row1_col4\" class=\"data row1 col4\" >squared_error</td>\n",
       "      <td id=\"T_60463_row1_col5\" class=\"data row1 col5\" >200</td>\n",
       "      <td id=\"T_60463_row1_col6\" class=\"data row1 col6\" >25</td>\n",
       "      <td id=\"T_60463_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_60463_row1_col8\" class=\"data row1 col8\" >0.0000</td>\n",
       "      <td id=\"T_60463_row1_col9\" class=\"data row1 col9\" >0.4000</td>\n",
       "      <td id=\"T_60463_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_60463_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60463_level0_row2\" class=\"row_heading level0 row2\" >56</th>\n",
       "      <td id=\"T_60463_row2_col0\" class=\"data row2 col0\" >minmax + random_forest</td>\n",
       "      <td id=\"T_60463_row2_col1\" class=\"data row2 col1\" >0.9268</td>\n",
       "      <td id=\"T_60463_row2_col2\" class=\"data row2 col2\" >83.2877</td>\n",
       "      <td id=\"T_60463_row2_col3\" class=\"data row2 col3\" >0.6600</td>\n",
       "      <td id=\"T_60463_row2_col4\" class=\"data row2 col4\" >squared_error</td>\n",
       "      <td id=\"T_60463_row2_col5\" class=\"data row2 col5\" >200</td>\n",
       "      <td id=\"T_60463_row2_col6\" class=\"data row2 col6\" >25</td>\n",
       "      <td id=\"T_60463_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_60463_row2_col8\" class=\"data row2 col8\" >0.0001</td>\n",
       "      <td id=\"T_60463_row2_col9\" class=\"data row2 col9\" >0.4000</td>\n",
       "      <td id=\"T_60463_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_60463_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60463_level0_row3\" class=\"row_heading level0 row3\" >57</th>\n",
       "      <td id=\"T_60463_row3_col0\" class=\"data row3 col0\" >minmax + random_forest</td>\n",
       "      <td id=\"T_60463_row3_col1\" class=\"data row3 col1\" >0.9267</td>\n",
       "      <td id=\"T_60463_row3_col2\" class=\"data row3 col2\" >83.4182</td>\n",
       "      <td id=\"T_60463_row3_col3\" class=\"data row3 col3\" >0.6600</td>\n",
       "      <td id=\"T_60463_row3_col4\" class=\"data row3 col4\" >squared_error</td>\n",
       "      <td id=\"T_60463_row3_col5\" class=\"data row3 col5\" >200</td>\n",
       "      <td id=\"T_60463_row3_col6\" class=\"data row3 col6\" >25</td>\n",
       "      <td id=\"T_60463_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_60463_row3_col8\" class=\"data row3 col8\" >0.0010</td>\n",
       "      <td id=\"T_60463_row3_col9\" class=\"data row3 col9\" >0.4000</td>\n",
       "      <td id=\"T_60463_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_60463_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_60463_level0_row4\" class=\"row_heading level0 row4\" >16</th>\n",
       "      <td id=\"T_60463_row4_col0\" class=\"data row4 col0\" >minmax + random_forest</td>\n",
       "      <td id=\"T_60463_row4_col1\" class=\"data row4 col1\" >0.9264</td>\n",
       "      <td id=\"T_60463_row4_col2\" class=\"data row4 col2\" >83.7465</td>\n",
       "      <td id=\"T_60463_row4_col3\" class=\"data row4 col3\" >0.6600</td>\n",
       "      <td id=\"T_60463_row4_col4\" class=\"data row4 col4\" >squared_error</td>\n",
       "      <td id=\"T_60463_row4_col5\" class=\"data row4 col5\" >500</td>\n",
       "      <td id=\"T_60463_row4_col6\" class=\"data row4 col6\" >25</td>\n",
       "      <td id=\"T_60463_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "      <td id=\"T_60463_row4_col8\" class=\"data row4 col8\" >0.0100</td>\n",
       "      <td id=\"T_60463_row4_col9\" class=\"data row4 col9\" >0.4000</td>\n",
       "      <td id=\"T_60463_row4_col10\" class=\"data row4 col10\" >nan</td>\n",
       "      <td id=\"T_60463_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5bc5c92290>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_tag = \"random_forest\"\n",
    "random_forest_step = Step(\n",
    "    estimator_tag,\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=RANDOM_STATE),\n",
    "    {\n",
    "        \"max_samples\": [0.66],\n",
    "        \"criterion\": [\"squared_error\"],\n",
    "        \"n_estimators\": [200],\n",
    "        \"max_depth\": [25],  # , 5, 10, 15, 20],\n",
    "        \"max_leaf_nodes\": [None],  # 50, 100, 200, 300, 400\n",
    "        \"ccp_alpha\": [0.0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "        \"max_features\": [0.4],  # \"sqrt\", \"log2\", 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9\n",
    "    },\n",
    ")\n",
    "\n",
    "combinations = MultiplePipes(\n",
    "    Pipe(random_forest_step),\n",
    "    Pipe(minmax_step, random_forest_step),\n",
    "    Pipe(minmax_step, pca_step, random_forest_step),\n",
    "    Pipe(features_remover_step, minmax_step, pca_step, random_forest_step),\n",
    ")\n",
    "grid_search(combinations, estimator_tag=estimator_tag)\n",
    "\n",
    "print_results(OUTPUT_FOLDER + estimator_tag + \"_output.csv\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combination 1/4  |  linear_regression\n",
      "\tParams {}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 2/4  |  minmax + linear_regression\n",
      "\tParams {}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 3/4  |  minmax + pca + linear_regression\n",
      "\tParams {'pca__n_components': [0.95]}\n",
      "  ==> Already done. Skipped.\n",
      "\n",
      "Combination 4/4  |  features_remover + minmax + pca + linear_regression\n",
      "\tParams {'features_remover__corr_threshold': [0.95], 'pca__n_components': [0.95]}\n",
      "  ==> Already done. Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_aaee3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aaee3_level0_col0\" class=\"col_heading level0 col0\" >tag</th>\n",
       "      <th id=\"T_aaee3_level0_col1\" class=\"col_heading level0 col1\" >R2</th>\n",
       "      <th id=\"T_aaee3_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_aaee3_level0_col3\" class=\"col_heading level0 col3\" >pca__n_components</th>\n",
       "      <th id=\"T_aaee3_level0_col4\" class=\"col_heading level0 col4\" >features_remover__corr_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aaee3_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_aaee3_row0_col0\" class=\"data row0 col0\" >minmax + linear_regression</td>\n",
       "      <td id=\"T_aaee3_row0_col1\" class=\"data row0 col1\" >0.7538</td>\n",
       "      <td id=\"T_aaee3_row0_col2\" class=\"data row0 col2\" >280.1071</td>\n",
       "      <td id=\"T_aaee3_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "      <td id=\"T_aaee3_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aaee3_level0_row1\" class=\"row_heading level0 row1\" >0</th>\n",
       "      <td id=\"T_aaee3_row1_col0\" class=\"data row1 col0\" >linear_regression</td>\n",
       "      <td id=\"T_aaee3_row1_col1\" class=\"data row1 col1\" >0.7538</td>\n",
       "      <td id=\"T_aaee3_row1_col2\" class=\"data row1 col2\" >280.1071</td>\n",
       "      <td id=\"T_aaee3_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_aaee3_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aaee3_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_aaee3_row2_col0\" class=\"data row2 col0\" >features_remover + minmax + pca + linear_regression</td>\n",
       "      <td id=\"T_aaee3_row2_col1\" class=\"data row2 col1\" >0.6677</td>\n",
       "      <td id=\"T_aaee3_row2_col2\" class=\"data row2 col2\" >378.1035</td>\n",
       "      <td id=\"T_aaee3_row2_col3\" class=\"data row2 col3\" >0.9500</td>\n",
       "      <td id=\"T_aaee3_row2_col4\" class=\"data row2 col4\" >0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aaee3_level0_row3\" class=\"row_heading level0 row3\" >2</th>\n",
       "      <td id=\"T_aaee3_row3_col0\" class=\"data row3 col0\" >minmax + pca + linear_regression</td>\n",
       "      <td id=\"T_aaee3_row3_col1\" class=\"data row3 col1\" >0.6527</td>\n",
       "      <td id=\"T_aaee3_row3_col2\" class=\"data row3 col2\" >395.1441</td>\n",
       "      <td id=\"T_aaee3_row3_col3\" class=\"data row3 col3\" >0.9500</td>\n",
       "      <td id=\"T_aaee3_row3_col4\" class=\"data row3 col4\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5bc585bcd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_tag = \"linear_regression\"\n",
    "linear_regression_step = Step(\n",
    "    estimator_tag,\n",
    "    LinearRegression(n_jobs=-1),\n",
    ")\n",
    "\n",
    "combinations = MultiplePipes(\n",
    "    Pipe(linear_regression_step),\n",
    "    Pipe(minmax_step, linear_regression_step),\n",
    "    Pipe(minmax_step, pca_step, linear_regression_step),\n",
    "    Pipe(features_remover_step, minmax_step, pca_step, linear_regression_step),\n",
    ")\n",
    "grid_search(combinations, estimator_tag=estimator_tag)\n",
    "\n",
    "print_results(OUTPUT_FOLDER + estimator_tag + \"_output.csv\", 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
